[toc]

&emsp;&emsp;在使用多线程编程的时候，我们需要注意线程之间共享数据的问题，这种问题基本上是对统一数据同时读写造成的，详细情况可以参考**计算机操作系统**，这里不多赘述。为了避免这种情况，我们可以使用几种方法来解决，一是给数据上**锁**（互斥元，mutex），这是本章的内容；二是**无锁编程**（lock-free programming），这将在后面的章节中讨论；还有一种方式是将对数据结构的操作更新为一个**事务**（transaction）。

## 一、使用互斥元保护共享数据

&emsp;&emsp;这里我们不过多介绍mutex的设计思想，我们主要介绍其在C++中的使用。

### 1.1 在C++中使用mutex

&emsp;&emsp;在C++中，通过构造std::mutex的实例创建互斥元，调用成员函数lock()来锁定它，调用成员函数unlock()来结果它。然而，直接调用成员函数是不推荐的做法，因为我们需要在函数*包括异常在内*的每个出口都调用unlock()。作为替代，STL提供来std::lock_guard类模板，实现了互斥元的RAII惯用语法；它在构造时锁定所给的互斥元，在析构时解锁所给的互斥元。下面是一个演示，std::mutex和std::lock_guard()都声明于&lt;mutex&gt;。

```cpp
#include <list>
#include <mutex>
#include <algorithm>

std::list<int> some_list;
std::mutex some_mutex;

// 向链表中添加元素
void add_to_list(int val)
{
    std::lock_guard<std::mutex> guard(some_mutex);
    some_list.push_back(val);
}

// 查找元素val是否在链表中
bool list_contains(int val)
{
    std::lock_guard<std::mutex> guard(some_mutex);

    return std::find(some_list.begin(), some_list.end(), val) 
        != some_list.end();
}
```

&emsp;&emsp;在上面的代码中，我们使用了一个全局mutex来对列表实施来保护。在通常的使用中，我们可以将它封装到一个类中，以private的形势来避免冲突。但值得注意的是，**传递引用和指针可能会造成越过mutex的情况**，下面来看一段糟糕的代码：

```cpp
/* ===== class : 数据类 ===== */
class data
{
private:
    int m_a;
public: 
    void DoSth();
}

/* ===== class : 封装数据类 ===== */
class data_wrapper
{
private:
    data m_data;
    std::mutex m_dataMutex;
public:
    template<typename Function>
    void ProcessData(Function func)
    {
        // 传递“受保护”的数据到func
        std::lock_guard<std::mutex> guard(m_dataMutex);
        func(m_data);
    }
}

data* unprotectedData;

// 一个恶意函数，用于获取data_wrapper中的&m_data
void malicious_func(data& protectedData)
{
    unprotectedData = & protectedData;
}

data_warpper dw;

void foo()
{
    dw.process_data(malicious_func);
    // unpData已经或得了data的引用，现在可以绕开mutex直接使用doSth
    unprotectedData->DoSth();
}
```

&emsp;&emsp;在上面的的代码中，我们通过foo，向data_wrapper传入一个恶意函数，或得了其m_data的引用。而获得了data的unprotectedData就可以绕过mutex无需锁定互斥元即可调用DoSth。所以，我们应当注意**不要将受保护数据的指针和引用传递到锁的范围之外，无论是从函数中返回它们、将其存放在外部可见的内存中，还是作为参数传递给用户提供的函数**。

### 1.2 发现接口中固有的竞争条件

&emsp;&emsp;回忆下我们的第一段代码，我们对一个list整体添加了保护，而不是对其中的每一个节点添加保护。如果是后者的话，我们在删除节点的时候仍然可能面对竞争问题。下面我们来看另一个例子：考虑在多线程中使用std::stack。下面是std::stack的接口（不包含构造函数）。

```cpp
bool empty() const;
size_t size() const;
T& top();
T const& top() const;
void push(T const&);
void push(T&&);
void pop();
void swap(stack&&);
```

&emsp;&emsp;我们可以将上述的top修改为非引用的方式，这样就遵循来我们在1.1中提出的准则。但是这样的stack仍然是存在风险的，考虑下面这种情况：

```cpp
std::stack<int> st;

if (!st.empty())                    // 1
{
    int const val = st.top();       // 2
    st.pop();                       // 3
    doSth(val);
}
```

假设现在st中有一个元素，现在有两个线程访问它，它们的顺序是这样的：

|           线程A           |           线程B           |
| :-----------------------: | :-----------------------: |
|      if(!st.empty())      |                           |
| int const val = st.top(); |      if(!st.empty())      |
|         st.pop();         | int const val = st.top(); |
|        doSth(val);        |         st.pop()          |
|                           |        doSth(val);        |

我们可以看到，在上述的1、2、3之间可能发生竞争，甚至在后面的doSth()未被调用就已经出栈，使得val所引用的对象为空。下面我们来看几种解决方法：

#### 1.2.1 T1:传入引用

&emsp;&emsp;我们考虑把接受出栈值的变量的引用，作为参数传递给pop()调用：

```cpp
int result;
st.pop(result);
```

这样的代码在大多数时候都试用，但是如果我们的stack里面存放的是一个vector，那么我们在pop之前都将要事先构造一个vector，这是不推荐的。同时，这要求传入对象是*可赋值的（operator=）*，而不仅仅是复制或者移动构造。

#### 1.2.2 T2:要求不引发异常的拷贝或移动构造函数

&emsp;&emsp;提供不引发异常的拷贝、移动构造函数。

#### 1.2.3 T3:返回指向出栈顶的指针

&emsp;&emsp;这种方法的优点是可以自由复制并且不会引发异常，随之而来的困难则是内存管理。对此我们可以使用std::shared_ptr来解决这一问题。

#### 1.2.4 实现线程安全的stack

&emsp;&emsp;我们通过对std::stack加锁的方式来实现线程安全。

```cpp
#include <exception>
#include <stack>
#include <mutex>
#include <memory>
#include <thread>

// 自定义异常
struct empty_stack : std::exception
{
    const char* what() const throw() 
    {
        std::cout << "empty stack!" << std::endl;
    }
};

template<typename T>
class ts_stack
{
private:
    std::stack<T> m_data;

    // 使用mutable允许bool empty() const修改
    mutable std::mutex m_mutex;

public:
    // 默认构造函数 do nothing
    ts_stack() { }

    // 拷贝构造
    ts_stack(const ts_stack& other)
    {
        std::lock_guard<std::mutex> lock(other.m_mutex);
        m_data = other.m_data;
    }

    // 禁止赋值
    ts_stack& operator=(const ts_stack&) = delete;

    // 入栈
    void push(T inputVal)
    {
        std::lock_guard<std::mutex> lock(this->m_mutex);
        m_data.push(inputVal);
    }

    // 以ptr方式出栈
    std::shared_ptr<T> pop()
    {
        std::lock_guard<std::mutex> lock(this->m_mutex);
        if (m_data.empty()) throw empty_stack();
        
        // res只能指向top()，const pointer to res
        std::shared_ptr<T> const res(std::make_shared<T>(m_data.top()));
        m_data.pop();
        return res;
    }

    // 以传值的方式出栈
    void pop(T& val)
    {
        std::lock_guard<std::mutex> lock(this->m_mutex);
        if (m_data.empty()) throw empty_stack();

        val = m_data.top();
        m_data.pop();
    }

    bool empty() const
    {
        std::lock_guard<std::mutex> lock(this->m_mutex);
        return m_data.empty();
    }
};
```

### 1.3 死锁

&emsp;&emsp;我们已经了解如何在线程之间共享数据，因为添加mutex我们遇到了新的麻烦：死锁。回忆哲学家就餐问题，如果每个哲学家们总是*先拿左边的筷子，再拿右边的筷子*那么就有可能造成死锁。下面我们来看一看在C++中如何处理死锁相关的问题。STL提供std::lock可以同时锁定两个或更多互斥元，下面我们来看一下它是如何运作的：

```cpp
class data;
void swap(data& lhs, data& rhs);

class X
{
private:
    data m_data;
    std::mutex m_mutex;
public:
    X(const data& p_data) : m_data(p_data) { }

    friend void swap(X& lhs, X& rhs)
    {
        // 避免两个参数引用同一对象，从而引发异常
        if (&lhs == &rhs)   return;

        // 锁定两个对象
        std::lock(lhs.m_mutex, rhs.m_mutex);

        // 构造lock_guard，使用std::adopt_lock参数告知其已经被锁定，避免在lg构造函数中重复锁定
        std::lock_guard<std::mutex> lock_lhs(lhs.m_mutex, std::adopt_lock);
        std::lock_guard<std::mutex> rock_lhs(rhs.m_mutex, std::adopt_lock);

        swap(lhs.m_data, rhs.m_data);
    }
};
```

这里我们只需要注意两点，一是在构造多个std::lock_guard对象之前调用lock进行锁定；二是构造lg对象时使用参数std::adopt_lock使其沿用mutex已有锁的权限。值得一提的是，std::lock在锁定lhs.m_mutex或者rhs.m_mutex时都可能引发异常，该异常传播出std::lock。

### 1.4 避免死锁的进一步指南

&emsp;&emsp;死锁并不一定全来自于锁定，在两个线程上相互调用join()同样可以引发死锁，即循环等待。避免死锁的规则简而言之是，**如果一个线程在等待你，那么你就不要等它**。

#### 1.4.1 避免嵌套锁

&emsp;&emsp;第一个思路是：如果你已经持有一个锁，就别再获取锁。如果你坚持这个准则，光凭使用锁是不可能导致死锁的，因为每个线程仅持有一个锁（想想每个哲学家只拿一根筷子吃饭）。如果要获取多个锁，应该以std::lock的单个动作来实现。

#### 1.4.2 持有锁时，避免调用用户提供的代码

&emsp;&emsp;举个例子，在我们的多线程安全stack中，在参数类型上的每一个操作都是用户提供的代码。为了避免死锁，我们应当避免这种操作，然而当操作无法避免时，我们需要新的准则。

#### 1.4.3 以固定顺序获取锁

&emsp;&emsp;这是在1.3中的例子，如果我们不能做到以std::lock单个动作实现锁定，那么次优做法是在每个线程中以相同顺序获得它们。

#### 1.4.4 使用锁层次

&emsp;&emsp;锁层次的思路是：给mutex分级，当持有高级锁时，允许持有低级锁；当持有低级锁时，不允许持有高级锁。下面是一个简单演示：
```cpp
// 两个具有不同层次等级的锁
Hierarchical_Mutex High_Level_Mutex(100);
Hierarchical_Mutex Low_Level_Mutex(50);

int do_low_level_stuff();
int do_high_level_stuff();

int low_level_func()
{
    std::lock_guard<Hierarchical_Mutex> lg(Low_Level_Mutex);
    return do_low_level_stuff();
}

int high_level_func()
{
    std::lock_guard<Hierarchical_Mutex> lg(High_Level_Mutex);
    return do_high_level_stuff();
}

// OK，它持有了高级锁再去持有低级锁
void thread_a()
{
    high_level_func();
    low_level_func();
}

// Not OK，它持有了低级锁，就不能持有比它更高级的锁
void thread_b()
{
    low_level_func();
    high_level_func();
}

```

&emsp;&emsp;下面我们来看一下如何实现Hierarchical_Mutex：

```cpp
class Hierarchical_Mutex
{
private:
    std::mutex m_internal_mutex;

    // 具体对象锁的层次值
    unsigned long const m_hierarchy_val;

    // 前一个线程使用的层次值
    unsigned long m_previous_hierarchy_val;

    // 当前线程所有锁的最小值，以保证新锁等级不能超过旧锁
    // 使用thread_local当前线程的层次值，在类外初始化为ULONG_MAX以保证第一次锁定能成功
    static thread_local unsigned long m_this_thread_hierarchy_val;

    void check_for_hierarchy_violation()
    {
        if(m_this_thread_hierarchy_val <= m_hierarchy_val)
        {
            throw std::logic_error("mutex hierarchy violated");
        }
    }

    // 更新当前线程锁的层次值
    void update_hierarchy_val()
    {
        m_previous_hierarchy_val = m_this_thread_hierarchy_val;
        m_this_thread_hierarchy_val = m_hierarchy_val;
    }

public:
    explicit Hierarchical_Mutex(unsigned long val):
        m_hierarchy_val(val),
        m_previous_hierarchy_val(0)
        { }
    
    void lock()
    {
        check_for_hierarchy_violation();
        m_internal_mutex.lock();
        update_hierarchy_val();
    }

    void unlock()
    {
        m_this_thread_hierarchy_val = m_previous_hierarchy_val;
        m_internal_mutex.unlock();
    }

    bool try_lock()
    {
        check_for_hierarchy_violation();
        if(!m_internal_mutex.try_lock())    return false;
        
        update_hierarchy_val();
        return true;
    }
};

// 初始化m_this_thread_hierarchy_val
thread_local unsigned long Hierarchical_Mutex::m_this_thread_hierarchy_val(ULONG_MAX);
```

&emsp;&emsp;我们来仔细看一下它是如何运作的，以上面的代码为例:
```cpp
Hierarchical_Mutex High_Level_Mutex(100);
Hierarchical_Mutex Low_Level_Mutex(50);

void thread_a()
{
    high_level_func();
    /*
        第一次锁定，m_this_thread_hierarchy_val(ULONG_MAX) > m_hierarchy_val(100)，锁定成功；
        更新：m_this_thread_hierarchy_val = 100
            m_previous_hierarchy_val = ULONG_MAX
    */
    low_level_func();
    /*
        第二次锁定，m_this_thread_hierarchy_val(100) > m_hierarchy_val(50)，锁定成功；
        更新：m_this_thread_hierarchy_val = 50
            m_previous_hierarchy_val = 100
    */

    // 解锁时由低向高，由lock_guard自行完成
}
```

### 1.5 使用std::unique_lock灵活锁定

